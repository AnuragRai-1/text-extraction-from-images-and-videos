{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing library to be used\n",
    "\n",
    "import os\n",
    "from fpdf import FPDF\n",
    "import cv2\n",
    "import pytesseract\n",
    "\n",
    "Executable = \"ffmpeg.exe\"\n",
    "input = \"VideoLecture4.mp4 \"\n",
    "if not(os.path.exists(\"C:/Users/HP User/Desktop/ML Workshop/img\")):\n",
    "    os.mkdir(\"C:/Users/HP User/Desktop/ML Workshop/img\")\n",
    "\n",
    "output=\"img/image%d.png\"\n",
    "\n",
    "# ffmpeg command for getting images from video\n",
    "\n",
    "cmd=Executable + \" -i \"+ input + \"-filter_complex \\\"select='gt(scene,0.05)',metadata=print:file=time.txt\\\" -vsync vfr \" + output \n",
    "os.system(cmd)\n",
    "\n",
    "imagelist=os.listdir(\"C:/Users/HP User/Desktop/ML Workshop/img\")\n",
    "\n",
    "# imagelist is the list with all image filenames\n",
    "for image in imagelist:\n",
    "    img = cv2.imread(\"C:/Users/HP User/Desktop/ML Workshop/img/\"+image)\n",
    "    if img is not None:\n",
    "        detector = cv2.CascadeClassifier(\"haarcascade_frontalface_alt (1).xml\")\n",
    "        faces=detector.detectMultiScale(img)\n",
    "        pytesseract.pytesseract.tesseract_cmd = 'C:\\\\Program Files\\\\Tesseract-OCR\\\\tesseract.exe'\n",
    "        text = pytesseract.image_to_string(img, config='')\n",
    "        if (len(text)<5) | (len(faces)>0) :\n",
    "            os.remove(\"C:/Users/HP User/Desktop/ML Workshop/img/\"+image)\n",
    "\n",
    "            \n",
    "pdf = FPDF()\n",
    "imagelist=os.listdir(\"C:/Users/HP User/Desktop/ML Workshop/img\")\n",
    "for image in imagelist:\n",
    "    pdf.add_page()\n",
    "    pdf.image(\"C:/Users/HP User/Desktop/ML Workshop/img/\"+image)\n",
    "\n",
    "pdf.output(\"Slides.pdf\", \"F\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries required for text transcript conversion\n",
    "\n",
    "import subprocess\n",
    "from ibm_watson import SpeechToTextV1\n",
    "from ibm_watson.websocket import RecognizeCallback, AudioSource\n",
    "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting audio file \n",
    "\n",
    "command = 'ffmpeg -i VideoLecture4.mp4 -ab 160k -ar 44100 -vn audio.wav'\n",
    "subprocess.call(command, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# credentials for connecting with IBM Watson\n",
    "\n",
    "\n",
    "apikey = 'TegrIibKeT6J3KaqEyDUjWd8jEURt3iTr7EQp7Y1x8TU'\n",
    "url = 'https://api.eu-gb.speech-to-text.watson.cloud.ibm.com/instances/e3accf22-7aea-44ff-8b8e-f8d354183b17'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calling speech to text service of IBM Watson\n",
    "\n",
    "authenticator = IAMAuthenticator(apikey)\n",
    "stt = SpeechToTextV1(authenticator=authenticator)\n",
    "stt.set_service_url(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#passing audio input to service \n",
    "\n",
    "with open('audio.wav', 'rb') as f:\n",
    "    res = stt.recognize(audio=f, content_type='audio/wav', model='en-AU_NarrowbandModel', continuous=True).get_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [result['alternatives'][0]['transcript'].rstrip() + '.' for result in res['results']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making .txt file from extracted text\n",
    "\n",
    "text = [para[0].title() + para[1:] for para in text]\n",
    "transcript = ''.join(text)\n",
    "with open('output.txt', 'w') as out:\n",
    "    out.writelines(transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
